{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eafa423e-311d-4f60-820c-8073fea02a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境重置成功!\n",
      "观察: [array([6.75237178, 2.7474508 , 8.15561182, 0.        , 0.        ,\n",
      "       0.        , 0.        ]), array([3.96704494, 4.27406802, 6.3245583 , 0.        , 0.        ,\n",
      "       0.        , 0.        ])]\n",
      "观察形状: [(7,), (7,)]\n",
      "随机动作: [array([9.43289 , 6.090355, 4.307592], dtype=float32), array([9.365489 , 3.9628537, 8.273278 ], dtype=float32)]\n",
      "执行成功! 奖励: [-3.82852009  2.01696638], 完成: False\n",
      "\n",
      "=== 回合 1 ===\n",
      "真实估值:\n",
      "  智能体 0: [6.75237178 2.7474508  8.15561182]\n",
      "  智能体 1: [3.96704494 4.27406802 6.3245583 ]\n",
      "出价:\n",
      "  智能体 0: [9.43289  6.090355 4.307592]\n",
      "  智能体 1: [9.365489  3.9628537 8.273278 ]\n",
      "分配结果:\n",
      "  智能体 0 获得物品: [0 1]\n",
      "  智能体 1 获得物品: [2]\n",
      "支付:\n",
      "  智能体 0: 13.33\n",
      "  智能体 1: 4.31\n",
      "效用:\n",
      "  智能体 0: -3.83\n",
      "  智能体 1: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "# 测试环境\n",
    "%run env.py\n",
    "env = CombinatorialAuctionEnv(n_agents=2, n_items=3, max_steps=5)\n",
    "obs = env.reset()\n",
    "print(\"环境重置成功!\")\n",
    "print(f\"观察: {obs}\")\n",
    "print(f\"观察形状: {[o.shape for o in obs]}\")\n",
    "\n",
    "# 测试一步执行\n",
    "actions = [env.action_space.sample() for _ in range(env.n_agents)]\n",
    "print(f\"随机动作: {actions}\")\n",
    "\n",
    "next_obs, rewards, done, info = env.step(actions)\n",
    "print(f\"执行成功! 奖励: {rewards}, 完成: {done}\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afcbfc71-d526-44f5-b39e-eeb4aef92933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MADDPG 初始化成功!\n",
      "MADDPG 生成的动作: [array([0.37231618, 0.53775936, 0.44884092], dtype=float32), array([0.44975576, 0.6657661 , 0.56756955], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 测试 MADDPG\n",
    "%run maddpg.py\n",
    "\n",
    "# 使用与环境相同的参数\n",
    "n_agents = 2\n",
    "obs_dims = [env.obs_dim] * n_agents  # 注意使用 env.obs_dim 而不是 env.n_items\n",
    "act_dims = [env.n_items] * n_agents\n",
    "\n",
    "maddpg = MADDPG(n_agents, obs_dims, act_dims)\n",
    "print(\"MADDPG 初始化成功!\")\n",
    "\n",
    "# 测试动作生成\n",
    "test_obs = env.reset()\n",
    "test_actions = maddpg.act(test_obs)\n",
    "print(f\"MADDPG 生成的动作: {test_actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47572702-6303-458a-9c89-2794f20833e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤奖励: [ 2.11409236 11.52363563], 累计奖励: 13.63772798495957\n",
      "步骤奖励: [ 2.11305282 11.510764  ], 累计奖励: 27.26154481207269\n",
      "步骤奖励: [ 2.11333094 11.50952971], 累计奖励: 40.88440546147432\n",
      "步骤奖励: [ 2.11354626 11.50805396], 累计奖励: 54.50600568125521\n",
      "步骤奖励: [ 2.11386515 11.50652605], 累计奖励: 68.12639688042148\n",
      "回合结束，总奖励: 68.12639688042148\n",
      "尝试更新 MADDPG...\n",
      "更新完成!\n"
     ]
    }
   ],
   "source": [
    "# 简化训练循环\n",
    "import numpy as np\n",
    "\n",
    "# 重置环境\n",
    "obs_list = env.reset()\n",
    "done = False\n",
    "episode_reward = 0\n",
    "\n",
    "while not done:\n",
    "    # 使用 MADDPG 生成动作\n",
    "    actions = maddpg.act(obs_list)\n",
    "    \n",
    "    # 执行动作\n",
    "    next_obs_list, rewards, done, info = env.step(actions)\n",
    "    episode_reward += np.sum(rewards)\n",
    "    \n",
    "    # 存储经验\n",
    "    maddpg.buffer.add((obs_list, actions, rewards, next_obs_list, done))\n",
    "    \n",
    "    # 更新观察\n",
    "    obs_list = next_obs_list\n",
    "    \n",
    "    print(f\"步骤奖励: {rewards}, 累计奖励: {episode_reward}\")\n",
    "\n",
    "print(f\"回合结束，总奖励: {episode_reward}\")\n",
    "\n",
    "# 尝试更新 MADDPG\n",
    "print(\"尝试更新 MADDPG...\")\n",
    "maddpg.update(batch_size=32)\n",
    "print(\"更新完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef68495-612c-4a95-a09f-d12270021c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
